# Contra Interview Assessment Submission

### Josh Hull, Senior Site Reliability Engineering Candidate
### October, 2023

- With naked candor and not a small sense of imposter syndrome (as a developer), I'll begin.  As I've mentioned in my thoroughly enjoyable interviews with Lillian and Doug, my background is not one of a traditional developer nor software engineer.  Througout my career, the definition of the IC roles I've filled have changed in title from sysAadmin, to devOps, to platform engineer, to SRE, but the deliverables have been the same: ensuring a performant, lower cost, secure, durable, scalable, and reliable series of platforms to meet the needs of two disctinct yet equally important customers: the production users who can be both paying- and non-paying consumers (in this case, independents and clients), while the other is the developer and engineering cohort that produces the released code into production which the first customer set consumes.
- While I've touched code in each of these roles, it's been to improve a teammate's submission with observability, query evaluation and refactoring, event handling, asyncronous calls, caching, and/or infrastructure migration, if evaluation of the solution running the stack proves that a move to the cloud or an improved hardware provision is warranted.
- As a result, it has been rare in my history to create something from scratch.  I would like to call out the open source tooling I created to present a set of API wrappers for kubernetes cluster administration, which is a small demonstration of my shell scripting abilities https://github.com/farmotive/kex, https://github.com/farmotive/klog, https://github.com/farmotive/kud, and https://github.com/farmotive/kpoof.  I created these because I needed them in my day-to-day operations of administering and improving massive and distributed kubernetes clusters, and (at the time) they did not exist in the wild.
- To create a feature flag GraphQL API for this exercise, then, in a few hours time in a language I've supported and optimized like nodeJS, is not a light task for me, and I'll be the first to say that the results are far from perfect, nor production ready.  I understand this exercise is to demonstrate one's thought process and acumen; I hope this submission meets that task.  Following are the steps I've taken (so far) to attempt to meet the challenge, and my thought processes.
1. I started by reviewing the code and building the environment.  One roadblock encountered is that on a new m2, SSL/TLS encryption using terminal is not the same as the terminal provided within vsCode, so connecting to a Render postgres instance required appending `?ssl=true` to the connection string and instantiating solely from Terminal.  With more time I'd resolve this and create documentation for others to avoid the same fate.
1. I then considered the data structure necessary to achieve the goal.  As the instructions stated full CRUD operations weren't the goal, I contemplated a minimal set of user and flag data to demonstrate functionality.
1. My first commits were comparing ChatGPT 4 and Github copilot's responses to a prompt designed to reflect both the end goal and the framework on which it will be compiled and instantiated.  I did this without exposing it to the codebase to see what output would match my approach.  Here is the chatGPT prompt: 

        "You are the world's most concise nodeJS backend developer.  With detailed comments and tests, build a lightweight feature flag management service by completing the following backend tasks:
            Build a GraphQL API which connects to an external postgresql db with slonik, that:
            - Exposes a GraphQL Mutation to target one or more users with a specific feature flag
            - Exposes a GraphQL Query that returns all users and their associated feature flags
            - Exposes a GraphQL Mutation to change the value of a feature flag for a specific user
        Assume the nodejs project and the database exist."

1. While the output could be a good starting point if one had more time to proceed, no tests were provided stating "space constraints", and there was enough drift from the goal that I didn't desire shoehorning the response into my commits.
1. My next step was to do in the real world what I've done throughout my career, and that's to evaluate and leverage the work of those before me.  While the majority of the PRs are for the other adventure (modals for the frontend assessment), there were a few submissions for the backend that proved very useful.  With more time I would have found these candidates on LinkedIn to see if any were now showing as Contra employees, using that result to limit my evaluation of the code to those candidates with successful submissions.  As the SRE role remains open, I deduced that these submissions, varying in complexity, completeness, and approach, were not a definitive reason most did not receive nor perhaps accept an offer.
1. I proceeded to address the items in my code that were clearly not working as intended.  These included some undefined data types that needed entry in `bin/generated/types.ts` as well as inclusion in `schema.graphql`
1. My final step prior to these notes and the loom recording was to phone a friend.  I have never assumed working in a vacuum to be a good approach, and some minor redirection and discussion about the effort was a healthy process to lend a bit of confidence to my imperfect attempt and submission.  The candor and code is mine, I would not put any of these gaffes on their shoulders.

- I'll conclude these notes with the next steps, in the real world, I would take were new BE API code presented to me for release into production.  Doug responsed to my question of the primary goals for the CTO (with whom I'm eager to meet) and himself in bringing on a veteran SRE, with more observability, reduced pager noise, and a fully instrumented suite of monitors to help reduce MTTR for regressions or other bugs that make it into production.  A close second imperative would be automating load testing across the stack and codebase.  To accomplish these goals would be an honor and well within my wheelhouse.  
1. First, by instrumenting opentelemetry (preferrably with https://honeycomb.io). 
1. Second, by spinning up a https://locust.io cluster for automated and ephemeral load testing. This cluster would be off until needed, run to completion with reports made available to the team, and then go idle and non-billing until the next load test request.

- It's been my honor to take part in this exercise. I appreciate the time it will take for Joseph or someone else to review this submission, and hope the process isn't too arduous. I look forward to the next chat, regardless of the outcome. 